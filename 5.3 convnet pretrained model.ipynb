{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "conv_base = tf.keras.applications.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import os, shutil, pathlib\n",
    "\n",
    "\n",
    "new_base_dir = pathlib.Path('./datasets/catsvdogssmall/')\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass 3 arguments\n",
    "1. ```weights```: specifies weight checkpoint from which to init model\n",
    "2. ```include_top``` refers to including densely connected classifier of the network  \n",
    "    i. default, densely connected classifier corresponds to 1000 classes from ImageNet  \n",
    "    ii. because using own densely connected classifier (2 classes cats and dogs) don't need to include it  \n",
    "3. ```input_shape``` shape of image tensors passed into network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 180, 180, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 180, 180, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 180, 180, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 90, 90, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 90, 90, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 90, 90, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 45, 45, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 45, 45, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 45, 45, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 45, 45, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 22, 22, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 22, 22, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 22, 22, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 11, 11, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 11, 11, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 5, 5, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll start by extracting features as NumPy arrays by calling the predict() method of the conv_base model on our training, validation, and testing datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting VGG16 features and corresponding labels\n",
    "import numpy as np\n",
    "def get_features_and_labels(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    for images, labels in dataset:\n",
    "        preprocessed_images = tf.keras.applications.vgg16.preprocess_input(images)\n",
    "        features = conv_base.predict(preprocessed_images)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    return np.concatenate(all_features), np.concatenate(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 709ms/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 621ms/step\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = get_features_and_labels(train_dataset)\n",
    "val_features, val_labels = get_features_and_labels(validation_dataset)\n",
    "test_features, test_labels = get_features_and_labels(test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```predict()``` only expects images, not labels but current dataset yields batches that contain both images and labels.  \n",
    "VGG16 expects inputs preprocessed with ```keras.applications.vgg16.preprocess_input``` which scales pixel values to appropriate range  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can define densely connected classifier, train on data and labels recorded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = tf.keras.Input(shape=(5, 5, 512))\n",
    "x = layers.Flatten()(inputs) \n",
    "x = layers.Dense(256)(x)\n",
    "# note use of dropout for regularization\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 4s 52ms/step - loss: 14.2078 - accuracy: 0.9265 - val_loss: 3.8766 - val_accuracy: 0.9690\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 4.5937 - accuracy: 0.9710 - val_loss: 11.5772 - val_accuracy: 0.9430\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 2.1948 - accuracy: 0.9830 - val_loss: 4.6484 - val_accuracy: 0.9700\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.9650 - accuracy: 0.9915 - val_loss: 11.3221 - val_accuracy: 0.9450\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 3s 51ms/step - loss: 1.0623 - accuracy: 0.9905 - val_loss: 4.5482 - val_accuracy: 0.9700\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.4556 - accuracy: 0.9960 - val_loss: 3.9634 - val_accuracy: 0.9780\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.4944 - accuracy: 0.9920 - val_loss: 7.0493 - val_accuracy: 0.9720\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.2256 - accuracy: 0.9985 - val_loss: 3.1391 - val_accuracy: 0.9790\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 3s 55ms/step - loss: 0.3440 - accuracy: 0.9960 - val_loss: 3.4644 - val_accuracy: 0.9820\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.3730 - accuracy: 0.9965 - val_loss: 3.5739 - val_accuracy: 0.9820\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 3s 49ms/step - loss: 0.2022 - accuracy: 0.9990 - val_loss: 4.0920 - val_accuracy: 0.9770\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 3s 47ms/step - loss: 0.1738 - accuracy: 0.9985 - val_loss: 4.7798 - val_accuracy: 0.9700\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 3s 52ms/step - loss: 0.9097 - accuracy: 0.9940 - val_loss: 4.8007 - val_accuracy: 0.9790\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 3s 54ms/step - loss: 0.0738 - accuracy: 0.9990 - val_loss: 5.2903 - val_accuracy: 0.9790\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 6.1812e-07 - accuracy: 1.0000 - val_loss: 5.1836 - val_accuracy: 0.9740\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 4s 62ms/step - loss: 0.1986 - accuracy: 0.9985 - val_loss: 6.1385 - val_accuracy: 0.9780\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 3s 53ms/step - loss: 0.1055 - accuracy: 0.9980 - val_loss: 5.9031 - val_accuracy: 0.9660\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 3s 50ms/step - loss: 0.1463 - accuracy: 0.9995 - val_loss: 5.9306 - val_accuracy: 0.9750\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.1149 - accuracy: 0.9990 - val_loss: 5.1932 - val_accuracy: 0.9770\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 3s 48ms/step - loss: 0.2398 - accuracy: 0.9985 - val_loss: 6.8635 - val_accuracy: 0.9760\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "            optimizer=\"rmsprop\",\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"feature_extraction.keras\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=20,\n",
    "    validation_data=(val_features, val_labels),\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THraining vwery fast because only have to deal with 2 dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history[\"accuracy\"]\n",
    "val_acc = history.history[\"val_accuracy\"]\n",
    "loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reach a validation accuracy of about 97%—much better than we achieved in the previous section with the small model trained from scratch. This is a bit of an unfair\n",
    "comparison, however, because ImageNet contains many dog and cat instances, which means that our pretrained model already has the exact knowledge required for the\n",
    "task at hand. This won’t always be the case when you use pretrained features. However, the plots also indicate that we’re overfitting almost from the start—\n",
    "despite using dropout with a fairly large rate. That’s because this technique doesn’t use data augmentation, which is essential for preventing overfitting with small image\n",
    "datasets. \n",
    "\n",
    "### Feature Extraction with data augmentation\n",
    "Freeze convolutional base  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 26\n",
      "This is the number of trainable weights after freezing the conv base: 0\n"
     ]
    }
   ],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False)\n",
    "\n",
    "# empties list of trainable weights of the layer or model\n",
    "conv_base.trainable = False\n",
    "\n",
    "# print list of trainable weights before and after freezing\n",
    "conv_base.trainable = True\n",
    "print(\"This is the number of trainable weights before freezing the conv base:\", len(conv_base.trainable_weights))\n",
    "\n",
    "conv_base.trainable = False\n",
    "print(\"This is the number of trainable weights after freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new model that chains together:\n",
    "1. Data augmentation stage\n",
    "2. Frozen convolutional base\n",
    "3. Dense classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "\n",
    "# apply data augmentation\n",
    "x = data_augmentation(inputs) \n",
    "\n",
    "# apply input value scaling\n",
    "x = keras.applications.vgg16.preprocess_input(x) \n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 8/63 [==>...........................] - ETA: 2:34 - loss: 101.2791 - accuracy: 0.6953"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\150NN\\5.3 convnet pretrained model.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m50\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m validation_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X32sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m callbacks\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X32sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = 50, \n",
    "    validation_data = validation_dataset,\n",
    "    callbacks= callbacks\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this setup, only the weights from the two Dense layers that we added will be trained. That’s a total of four weight tensors: two per layer (the main weight matrix\n",
    "and the bias vector). \n",
    "\n",
    "Note that in order for these changes to take effect, you must first compile the model. If you ever modify weight trainability after compilation, you\n",
    "should then recompile the model, or these changes will be ignored. \n",
    "\n",
    " Let’s train our model. Thanks to data augmentation, it will take much longer for\n",
    "the model to start overfitting, so we can train for more epochs—let’s do 50\n",
    "\n",
    "## Fine Tuning\n",
    "Slightly adjust more abstract representations of the model being reused to make them more relevent for current task\n",
    "\n",
    "1. Add our custom network on top of an already-trained base network.\n",
    "2. Freeze the base network.\n",
    "3. Train the part we added.\n",
    "4. Unfreeze some layers in the base network.   \n",
    "    i. (Note that you should not unfreeze “batch normalization” layers, which are not relevant \n",
    "        here since there are no such layers in VGG16.  \n",
    "    ii. Batch normalization and its impact on fine tuning is explained in the next chapter.)\n",
    "5. Jointly train both these layers and the part we added.\n",
    "\n",
    "Steps 1 - 3 already done during feature extraction\n",
    "\n",
    "Fine tune last 3 conv layers, freeze up to block4_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why not fine tune more layers?\n",
    "1. Earlier layers encode more generic reusable features, later layers more specialized features. More useful to fine-tune more specialized features b/c these are ones to be repurposed on new problem  \n",
    "2. More paramaters training, the more at risk of overfitting. Conv base has 15m parameters, risk to attempt to train on small dataset. \n",
    "\n",
    "Small dataset => good strategy to fine-tune top 2 or 3 layers in  conv base. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze everything up to last 4 layers\n",
    "conv_base.trainable = True\n",
    "for layer in conv_base.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-5),\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"fine_tuning.keras\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_loss\")\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 2/63 [..............................] - ETA: 3:32 - loss: 3.4426 - accuracy: 0.9375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hugho\\Documents\\datascience\\150NN\\5.3 convnet pretrained model.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X40sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X40sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hugho/Documents/datascience/150NN/5.3%20convnet%20pretrained%20model.ipynb#X40sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\hugho\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fc6efb3340bf4aae142c4471c3414bb5b17e6e80ba42a259676c40f0503db89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
