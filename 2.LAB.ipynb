{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run MNIST\n",
    "- Add a text cell and comment on network training and test accuracy\n",
    "- Train for 20 epochs and evaluate. Comment on your findings\n",
    "- The first layer transforms the 784-element image vector to a 512 dimensional intermediate representation Experiment with different intermediate dimensions. Make a markdown table of network performance on the test set for varying intermediate dimension. Comment on your results\n",
    "- Replace network compilation with \n",
    "```\n",
    "from tensorflow.keras import optimizers\n",
    "network.compile(optimizer=optimizers.RMSprop(lr=0.001, momentum=0.0),\n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])\n",
    "```\n",
    "The code is exactly equivalent, but we are now able to adjust learning rate and momentum. `lr=0.001` is the default value: experiment with different learning rates. Tabulate your results and interpret\n",
    "- Experiment with different momentums. Tabulate and interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor shape\n",
      "\ttraining images: (60000, 28, 28)\n",
      "\ttraining labels: (60000,)\n",
      "\ttest images: (10000, 28, 28)\n",
      "\ttest labels: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "\n",
    "# load\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print('tensor shape')\n",
    "print('\\ttraining images:', train_images.shape)\n",
    "print('\\ttraining labels:', train_labels.shape)\n",
    "print('\\ttest images:', test_images.shape)\n",
    "print('\\ttest labels:', test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess\n",
    "\n",
    "1. Reshape to flatten 28x28 array to a vector containing 784 elements \n",
    "2. Cast vector as floats \n",
    "3. Rescale from [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "\n",
    "# reshape flattens 28x28 array to a vector of 784 elements\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "\n",
    "\n",
    "# cast as floats and rescale from [0,1]\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot Encoding\n",
    "Network requires categorically encoded labels\n",
    "\n",
    "encode with the ```to_categorical``` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'7'as one-hot vector:\t[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# encode with the to_categorical function\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "orig_label = test_labels[0]\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "print('\\'', orig_label, '\\'', 'as one-hot vector:\\t', test_labels[0], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buliding Network\n",
    "\n",
    "Sequential: model is a series of transformational layers. Data moves in a single forward direction through the network. A fit forward NN.\n",
    "\n",
    "Each layer has specific attributes which we'll investigate later\n",
    "\n",
    "2nd ```softmax``` layer outputs a vector whose elements form a **probability distribution**\n",
    "- numbers are nonnegative and sum to one => prob distribution\n",
    "- outputs are interperted as probs of membership of each class\n",
    "    - the prob that the input sample is label 0, 1, 2 etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build\n",
    "from tensorflow.keras import models, layers\n",
    "\n",
    "# create empty network\n",
    "network = models.Sequential()\n",
    "\n",
    "# add 2 layers\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28, )))\n",
    "network.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up For Traning\n",
    "Must specify:\n",
    "1. **A loss function**: quantifies how farr off network prediction is from target \n",
    "    - ```categorical_crossentropy```: preferred loss for single label multiclass problems\n",
    "2. **Optimizer**: makes parameter adjustments in the training loop\n",
    "    - ```rmsprop```\n",
    "3. One or more **training metrics**: report on progress\n",
    "    - ```accuracy```: fraction of correctly classified samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy', \n",
    "               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network\n",
    "Optimizer (rmsprop) tweaks layer parameters, weights, and biases.  \n",
    "Sliders are adjusted to attempt to lower the loss  \n",
    "\n",
    "Have to decide on:\n",
    "1. **Mini-Batch Size**: Number of samples processed in a single pass of the algorithm\n",
    "2. **Number of Epochs**: Number of complete passes through entire training set\n",
    "\n",
    "Suppose a training set has 32,768 samples. How many samples are processed training by the command:  \n",
    "```network.fit(train_images, train_labels, epochs=5, batch_size=128)```?  \n",
    "*32768 x 5*\n",
    "\n",
    "Suppose a training set has 32,768 samples. How many mini-batches are passed through the network by the command:   \n",
    "```network.fit(train_images, train_labels, epochs=5, batch_size=128)```?  \n",
    "*256 x 5*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2345 Gradient updates = 60000/128 (batch size) * 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 5s 9ms/step - loss: 0.2565 - accuracy: 0.9261\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 4s 10ms/step - loss: 0.1058 - accuracy: 0.9685\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 4s 10ms/step - loss: 0.0693 - accuracy: 0.9793\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0498 - accuracy: 0.9853\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0375 - accuracy: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x295703b65c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train\n",
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Network\n",
    "NN generally perform less well on new data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9785\n"
     ]
    }
   ],
   "source": [
    "# evaluate on the test set\n",
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 156ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.0968488e-09, 5.2965782e-10, 7.4819457e-07, 8.3084633e-06,\n",
       "        3.9866253e-12, 3.3456447e-09, 9.7639360e-15, 9.9998999e-01,\n",
       "        1.7995653e-07, 7.7392184e-07]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network prediction for a single sample\n",
    "# ten numbers, each a probability of class membership\n",
    "network.predict(test_images[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the most probable Class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(network.predict(test_images[:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#breaks code\n",
    "# plt.imshow(test_images[0], cmap=plt.cm.binary)\n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "2fc6efb3340bf4aae142c4471c3414bb5b17e6e80ba42a259676c40f0503db89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
